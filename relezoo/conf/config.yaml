defaults:
  - _self_
  - environments@env_train: classic_control/cartpole
  - environments@env_test: classic_control/cartpole
  - algorithm: reinforce-discrete
  - logger: tensorboard
  - override hydra/help: relezoo-help
  - override hydra/launcher: joblib-custom

##########################
## Experiment wise vars ##
##########################
context:
  experiment_name: Relezoo
  mode: train  # train, resume, play
  eval_every: 1
  render: False
  render_every: 1
  render_fps: 16
  mean_reward_window: 100
  checkpoints: checkpoints/
  resume_from: # previous checkpoint path to resume from
  start_at_step: 0 # set this to a specific step to start from if resuming from a previous run
  epochs: 50
  seed:
  gpu: True # use gpu if available

network:
  infer_in_shape: True
  infer_out_shape: True


##########################
### Runtime wise vars ####
##########################
ray:
  init:
    num_cpus: 4
    #4GB in bytes
    _memory: 4294967296
    ignore_reinit_error: True

hydra:
  run:
    dir: outputs/${context.experiment_name}/${now:%Y-%m-%d_%H-%M-%S}

  sweep:
    dir: outputs/${context.experiment_name}/multirun
    subdir: ${hydra.job.num}/${now:%Y-%m-%d_%H-%M-%S}